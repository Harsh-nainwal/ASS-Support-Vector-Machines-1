{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b91801-4a97-408f-a79f-0c304398f23e",
   "metadata": {},
   "source": [
    "Q1. What is the mathematical formula for a linear SVM?\n",
    "\n",
    "Ans:-\n",
    "\n",
    "A Support Vector Machine (SVM) is a machine learning algorithm used for classification and regression tasks. The formula for a linear SVM's decision boundary is:\n",
    "    w · x + b = 0\n",
    "\n",
    "Here, w represents the weights of the features, **x** is the input feature vector, and b is the bias term.\n",
    "\n",
    "Q2. What is the objective function of a linear SVM?\n",
    "\n",
    "Ans:-\n",
    "\n",
    "\n",
    "The objective of a linear SVM is to find the optimal decision boundary that maximizes the margin between different classes while minimizing the classification error. The mathematical representation of the objective function is:\n",
    "\n",
    "Minimize: (1/2) * ||w||^2\n",
    "Subject to: y_i * (w · x_i + b) ≥ 1 for all training samples (x_i, y_i)\n",
    "\n",
    "In this formula, w is the weight vector, **b** is the bias term, x_i represents the feature vectors of the training samples, and **y_i** is the corresponding class label (-1 or 1).\n",
    "\n",
    "Q3. What is the kernel trick in SVM?\n",
    "\n",
    "Ans:-\n",
    "\n",
    "\n",
    "The kernel trick is a powerful concept in SVM that allows the algorithm to find non-linear decision boundaries by mapping the original feature space into a higher-dimensional space. The kernel function computes the dot product of the mapped feature vectors in this higher-dimensional space without explicitly calculating the mapping. This way, SVM can effectively capture complex relationships between features.\n",
    "\n",
    "Common kernel functions include polynomial, radial basis function (RBF), and sigmoid kernels.\n",
    "\n",
    "Q4. What is the role of support vectors in SVM? Explain with an example:\n",
    "\n",
    "Ans:-\n",
    "\n",
    "\n",
    "Support vectors are the data points that lie closest to the decision boundary in an SVM. They have the most influence on determining the position and orientation of the decision boundary. These points are important because they directly affect the margin and the overall performance of the SVM.\n",
    "\n",
    "Imagine you have two classes of animals:\n",
    "\n",
    "dogs and cats. You want to use an SVM to classify them based on their weight and height. The support vectors in this case would be the animals that are closest to the decision boundary (the one that maximizes the margin between the classes). These animals are critical because they are the ones that help define the boundary between dogs and cats.\n",
    "\n",
    "For example, if you have a small dog and a big cat that are very close to each other, these two animals might be the support vectors. The SVM would adjust the decision boundary to make sure it's correctly positioned between these two critical animals, while also keeping the margin as wide as possible.\n",
    "\n",
    "I hope these explanations help clarify the concepts! If you have more questions or need further details, feel free to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4a71c2-0be3-4899-a9a9-fa3f3ce1c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1880625-c9d0-44ea-9ea2-a9e144f52bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9419fc-96d4-4f18-8470-72097d43beb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2644daae-8aad-4b13-958d-5369650f29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the testing set\n",
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb4295d-074a-4036-8692-dd987aa22b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1ab1ec-7709-4172-aa10-0a3f3142c394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3d5b1b-978c-416e-9ae1-18bcb03ad3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "accuracies = []\n",
    "\n",
    "for C in C_values:\n",
    "    # Train a linear SVM classifier with the current C value\n",
    "    svm_classifier = SVC(kernel='linear', C=C)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict labels for the testing set\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    # Compute the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02b9166-01c0-46d3-86e9-e4753319635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a2160-a135-4531-bfe0-84ae0bd0cbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
